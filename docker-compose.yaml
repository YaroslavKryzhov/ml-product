version: "3.4"

services:
  server:
    container_name: "ml-product-server"
    build:
      context: ./server
      dockerfile: Dockerfile
    command: "poetry run uvicorn ml_api.main:app --workers 4 --host 0.0.0.0 --port 8006 --reload"
    # command: "poetry run gunicorn -k uvicorn.workers.UvicornWorker ml_api.main:app --bind 0.0.0.0:8006 --workers 4"
    env_file:
      - .env
    volumes:
      - ./volumes/server_data:/data/
      - ./server:/server
    depends_on:
      - mongo_db
      - worker
    networks:
      - ml-net
    restart: unless-stopped
    ports:
      - "8006:8006"

  worker:
    container_name: "ml-product-worker"
    build:
      context: ./server
      dockerfile: Dockerfile
    command: "poetry run celery -A ml_api.celery_worker.app_celery worker --loglevel=info -c 4"
    env_file:
      - .env
    volumes:
      - ./volumes/server_data:/data/
      - ./server:/server
    depends_on:
      - rabbitmq
      - mongo_db
      - centrifugo
    networks:
      - ml-net

  rabbitmq:
    container_name: "ml-product-rabbitmq"
    image: "rabbitmq:3-management"
#    environment:
#      RABBITMQ_DEFAULT_USER: "${RABBITMQ_DEFAULT_USER}"
#      RABBITMQ_DEFAULT_PASS: "${RABBITMQ_DEFAULT_PASS}"
    env_file:
      - .env
    ports:
      - "15672:15672"
    volumes:
      - ./volumes/rabbitmq_data:/var/lib/rabbitmq
    networks:
      - ml-net
    restart: unless-stopped

  centrifugo:
    container_name: "ml-product-centrifugo"
    image: centrifugo/centrifugo:v2.8.7
    volumes:
      - ./deploy/centrifugo/config.json:/centrifugo/config.json
    command: centrifugo -c config.json
    env_file:
      - .env
    ulimits:
      nofile:
        soft: 65535
        hard: 65535
    networks:
      - ml-net

  mongo_db:
    container_name: "ml-product-mongo"
    build:
      context: ./deploy/mongodb
      dockerfile: Dockerfile
    env_file:
      - .env
    volumes:
      - ./volumes/mongo_data:/data/db
    ports:
      - "${MONGO_PORT_OUT}:27017"
    networks:
      - ml-net
    restart: unless-stopped

  # client:
  #   container_name: "ml-product-client"
  #   build:
  #     context: ./client
  #     dockerfile: Dockerfile
  #   volumes:
  #     - ./volumes/client:/build_results/build/
  #   command: "/bin/sh -c 'cp -r /app/build /build_results/'"

  #   networks:
  #    - ml-net

  nginx:
    build:
      context: ./deploy/nginx
      dockerfile: Dockerfile
    container_name: "ml-product-nginx"
    env_file:
      - .env
    depends_on:
      - server
    volumes:
      - ./deploy/nginx/nginx.conf:/etc/nginx/conf.d/nginx.conf
      - ./volumes/client:/usr/share/nginx/html:ro
    command: "/bin/sh -c 'while :; do sleep 5h & wait $${!}; nginx -s reload; done & nginx-debug -g \"daemon off;\"'"
    ports:
      - "${API_PORT_OUT}:80"
    networks:
      - ml-net
  
  front:
    build: ./client
    restart: unless-stopped
    ports:
      - "3001:3000"
  

networks:
  ml-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.167.0.0/24